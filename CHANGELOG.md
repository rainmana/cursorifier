# Changelog

All notable changes to this project will be documented in this file.

## [0.1.4] - 2025-01-21

### Added
- ğŸ”Œ **Multi-Provider LLM Support**: Added support for Anthropic Claude, OpenAI, and local models (Ollama, LM Studio)
- ğŸ  **Local AI Integration**: Use your own models with Ollama or LM Studio
- ğŸ“ **Repomix File Support**: Added `--repomix-file` option to use existing repomix output files
- âš™ï¸ **Enhanced Configuration**: Added `--model`, `--api-key`, `--base-url`, `--max-tokens`, `--temperature` options
- ğŸ¯ **Better Error Handling**: Improved error messages and validation
- ğŸ“‹ **Provider Listing**: Added `--list-providers` option to show available providers and models
- ğŸ¤– **Cline Rules Support**: Added `--output-format cline` option to generate `.clinerules` files for Cline AI assistant
- ğŸ“ **Dual Format Support**: Generate both Cursor AI (`.rules.mdc`) and Cline (`.clinerules`) formats

### Changed
- ğŸ·ï¸ **Project Renamed**: Renamed from `rulefy` to `cursorifier` to avoid conflicts
- ğŸ“¦ **Binary Renamed**: Command changed from `rulefy` to `cursorifier`
- ğŸ”§ **Enhanced CLI**: More granular control over LLM parameters

### Technical Details
- Added provider interface system for extensible LLM support
- Implemented Anthropic, OpenAI, and Local providers
- Added comprehensive error handling and validation
- Maintained backward compatibility with existing functionality

### Credits
This is a fork of the original [rulefy](https://github.com/niklub/rulefy) project by [niklub](https://github.com/niklub), enhanced with multi-provider LLM support and additional features.